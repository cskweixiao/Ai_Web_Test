# 产品需求文档：AI断言稳定性优化系统

## 1. 项目概述

### 1.1 背景介绍
Sakura AI自动化测试平台当前的AI断言系统存在稳定性问题，主要表现为：
- 断言误报率高，网络波动或页面加载延迟导致测试失败
- 单点失败机制，任何一个断言失败都会导致整个测试失败
- 关键词匹配过于死板，页面文案微调就需要更新测试用例
- 缺乏智能重试和容错机制

### 1.2 项目目标
本项目旨在全面提升AI断言系统的稳定性和可靠性，具体目标包括：
- **降低误报率**：从当前20%降至4%以下
- **提高准确性**：减少因临时性问题导致的测试失败
- **增强可靠性**：确保核心功能验证的稳定执行
- **提升易用性**：减少因页面细微变化需要的维护工作

## 2. 具体目标

1. **误报率降低80%**：通过智能重试和多策略验证，将断言误报率从20%降至4%
2. **测试稳定性提升90%**：消除网络抖动、页面加载延迟等临时性问题的影响
3. **维护成本降低70%**：页面文案小幅调整不再需要修改测试用例
4. **执行效率优化**：在保证稳定性的前提下，性能影响控制在10%以内
5. **用户体验提升**：提供清晰的断言执行报告和配置界面

## 3. 用户故事

### 3.1 测试工程师视角
- **作为测试工程师**，我希望断言能够智能重试，以便临时的网络问题不会导致测试失败
- **作为测试工程师**，我希望能够设置断言的重要级别，以便关键断言和辅助断言区别对待
- **作为测试工程师**，我希望断言支持模糊匹配，以便页面文案小改动不影响测试执行

### 3.2 开发人员视角
- **作为开发人员**，我希望看到详细的断言失败原因，以便快速定位问题
- **作为开发人员**，我希望非关键断言失败不阻塞测试，以便看到完整的测试结果

### 3.3 项目管理者视角
- **作为项目管理者**，我希望看到断言执行的统计报告，以便了解系统稳定性趋势
- **作为项目管理者**，我希望降低测试维护成本，以便团队专注于新功能开发

## 4. 功能需求

### 4.1 三级断言体系
**需求编号**: FR-001
**描述**: 系统必须支持三级断言分类机制

**详细要求**：
1. **关键断言(Critical)**
   - 失败时立即停止测试执行
   - 记录详细的错误信息和截图
   - 触发告警通知
   - 示例：登录验证、支付成功确认

2. **重要断言(Important)**
   - 失败时记录警告但继续执行
   - 生成警告级别的日志
   - 在报告中标记为需关注项
   - 示例：页面元素显示、非核心功能验证

3. **可选断言(Optional)**
   - 失败时仅记录信息
   - 不影响测试结果判定
   - 用于收集补充信息
   - 示例：性能指标、UI细节验证

### 4.2 智能重试机制
**需求编号**: FR-002
**描述**: 系统必须实现基于失败类型的智能重试

**详细要求**：
1. **重试策略**
   - 根据失败类型自动决定是否重试
   - 网络超时类：自动重试3次
   - 元素未找到类：等待后重试2次
   - 文本不匹配类：使用不同匹配策略重试

2. **重试配置**
   - 默认重试3次，间隔2秒
   - 支持递增延迟（1秒、2秒、4秒）
   - 可针对不同断言类型配置不同策略

3. **重试日志**
   - 记录每次重试的原因和结果
   - 统计重试成功率
   - 生成重试分析报告

### 4.3 多策略文本验证
**需求编号**: FR-003
**描述**: 系统必须支持多种文本匹配策略

**详细要求**：
1. **精确匹配**
   - 完全匹配指定文本
   - 支持大小写敏感/不敏感选项

2. **模糊匹配**
   - 相似度阈值可配置（默认80%）
   - 支持编辑距离算法
   - 自动处理空格和标点差异

3. **语义匹配**
   - 支持同义词替换
   - 识别相似表达
   - 中英文混合支持

4. **部分匹配**
   - 包含指定关键词即可
   - 支持多个关键词的AND/OR逻辑
   - 支持正则表达式

### 4.4 页面稳定性检测
**需求编号**: FR-004
**描述**: 系统必须在断言前确保页面处于稳定状态

**详细要求**：
1. **网络请求检测**
   - 等待所有XHR/Fetch请求完成
   - 检测WebSocket连接状态
   - 超时时间可配置（默认5秒）

2. **DOM稳定性检测**
   - 监控DOM变化频率
   - 等待DOM停止变化超过500ms
   - 检测动画和过渡效果完成

3. **加载状态检测**
   - 检测加载动画消失
   - 等待图片资源加载
   - 验证关键元素渲染完成

### 4.5 断言执行报告
**需求编号**: FR-005
**描述**: 系统必须提供详细的断言执行报告

**详细要求**：
1. **执行详情**
   - 断言描述和预期结果
   - 实际执行结果
   - 匹配策略和置信度
   - 重试次数和每次结果

2. **失败分析**
   - 失败原因分类
   - 页面快照和关键词位置
   - 建议的修复方案

3. **统计信息**
   - 断言通过率趋势
   - 平均执行时间
   - 重试成功率
   - 最常失败的断言TOP10

### 4.6 简单配置界面
**需求编号**: FR-006
**描述**: 系统必须提供用户友好的配置界面

**详细要求**：
1. **全局配置**
   - 默认重试次数和间隔
   - 默认匹配策略
   - 超时时间设置

2. **断言级配置**
   - 断言级别选择（关键/重要/可选）
   - 自定义重试策略
   - 匹配方式选择

3. **高级配置**
   - 同义词词库管理
   - 忽略规则设置
   - 自定义验证脚本

## 5. 非功能性需求

### 5.1 性能要求
- 断言执行时间增加不超过10%
- 重试机制不能造成资源泄露
- 支持并发执行多个测试套件

### 5.2 兼容性要求
- 100%兼容现有测试用例格式
- 支持渐进式升级
- 提供回退机制

### 5.3 可靠性要求
- 系统可用性达到99.9%
- 断言验证准确率达到95%以上
- 支持断言执行的事务性

### 5.4 可维护性要求
- 代码覆盖率达到80%以上
- 提供完整的API文档
- 支持插件式扩展

## 6. 项目范围外（不包含）

以下功能不在本次项目范围内：
1. 视觉回归测试（截图对比）
2. 性能断言（响应时间、资源占用）
3. 安全性断言（XSS、SQL注入检测）
4. 跨浏览器兼容性测试
5. 移动端适配测试
6. 国际化/多语言支持
7. 断言的AI自动生成
8. 测试用例的自动修复

## 7. 技术方案（建议）

### 7.1 架构设计
```
┌─────────────────────────────────────────┐
│         AI断言稳定性优化系统              │
├─────────────────────────────────────────┤
│  配置层                                   │
│  ├─ 全局配置管理                         │
│  ├─ 断言级别配置                         │
│  └─ 策略配置中心                         │
├─────────────────────────────────────────┤
│  执行层                                   │
│  ├─ 页面稳定性检测器                     │
│  ├─ 智能重试引擎                         │
│  ├─ 多策略验证器                         │
│  └─ 断言执行器                           │
├─────────────────────────────────────────┤
│  分析层                                   │
│  ├─ 失败原因分析                         │
│  ├─ 统计数据收集                         │
│  └─ 报告生成器                           │
├─────────────────────────────────────────┤
│  数据层                                   │
│  ├─ 断言配置存储                         │
│  ├─ 执行历史记录                         │
│  └─ 统计数据存储                         │
└─────────────────────────────────────────┘
```

### 7.2 关键技术点
1. **智能重试算法**：基于失败类型的自适应重试
2. **模糊匹配引擎**：Levenshtein距离 + 同义词库
3. **页面稳定检测**：MutationObserver + Performance API
4. **并发控制**：Promise队列 + 资源池管理

### 7.3 数据库变更
```sql
-- 新增断言配置表
CREATE TABLE assertion_configs (
  id INT PRIMARY KEY,
  test_case_id INT,
  assertion_level ENUM('critical', 'important', 'optional'),
  retry_config JSON,
  match_config JSON,
  created_at TIMESTAMP,
  updated_at TIMESTAMP
);

-- 新增断言执行历史表
CREATE TABLE assertion_history (
  id INT PRIMARY KEY,
  run_id VARCHAR(100),
  assertion_id INT,
  retry_count INT,
  success BOOLEAN,
  failure_reason VARCHAR(500),
  execution_time INT,
  created_at TIMESTAMP
);
```

## 8. 成功指标

### 8.1 量化指标
1. **稳定性指标**
   - 断言误报率 < 4%
   - 重试成功率 > 60%
   - 测试通过率提升 > 30%

2. **性能指标**
   - 平均执行时间增加 < 10%
   - 并发执行能力不降低
   - 资源占用增加 < 20%

3. **可维护性指标**
   - 测试用例修改频率降低 70%
   - 平均问题定位时间减少 50%
   - 用户满意度 > 85%

### 8.2 定性指标
- 用户反馈积极
- 开发团队接受度高
- 系统运行稳定可靠

## 9. 实施计划

### 第一阶段（第1周）- 核心功能
1. **Day 1-2**: 实现智能重试机制
   - 基础重试框架
   - 失败类型识别
   - 重试策略配置

2. **Day 3-4**: 实现多策略文本验证
   - 模糊匹配算法
   - 同义词支持
   - 策略选择器

3. **Day 5**: 实现三级断言体系
   - 断言级别定义
   - 执行流程改造
   - 失败处理逻辑

### 第二阶段（第2周）- 完善优化
1. **Day 6-7**: 实现页面稳定性检测
   - 网络请求监控
   - DOM变化检测
   - 加载状态判断

2. **Day 8-9**: 开发配置界面
   - 全局配置页面
   - 断言配置组件
   - 配置持久化

3. **Day 10-12**: 报告和分析
   - 执行报告生成
   - 统计数据收集
   - 趋势分析图表

4. **Day 13-14**: 测试和优化
   - 集成测试
   - 性能优化
   - 文档完善

## 10. 风险评估

### 10.1 技术风险
| 风险项 | 概率 | 影响 | 缓解措施 |
|--------|------|------|----------|
| 重试机制导致执行时间过长 | 中 | 高 | 设置最大重试时间上限 |
| 模糊匹配准确度不足 | 中 | 中 | 提供多种匹配策略组合 |
| 页面检测误判 | 低 | 中 | 提供手动覆盖选项 |
| 兼容性问题 | 低 | 高 | 充分测试，提供回退方案 |

### 10.2 项目风险
| 风险项 | 概率 | 影响 | 缓解措施 |
|--------|------|------|----------|
| 开发周期延长 | 中 | 中 | 分阶段交付，优先核心功能 |
| 需求变更 | 低 | 中 | 明确需求边界，及时沟通 |
| 资源不足 | 低 | 高 | 提前规划，必要时调整范围 |

## 11. 依赖关系

### 11.1 技术依赖
- Playwright 浏览器自动化框架
- MCP (Model Context Protocol) 协议
- MySQL 数据库
- Node.js + Express 后端框架
- React + TypeScript 前端框架

### 11.2 团队依赖
- 前端开发：配置界面开发
- 后端开发：核心逻辑实现
- 测试团队：验收测试
- 产品团队：需求确认

## 12. 待明确问题

1. 是否需要支持自定义断言插件？
2. 历史数据保留多长时间？
3. 是否需要导出断言配置功能？
4. 是否需要断言模板库？
5. 是否支持批量配置断言？
6. 失败告警通知方式（邮件、webhook等）？

## 13. 附录

### 13.1 术语定义
- **断言(Assertion)**：测试执行中的验证点
- **误报(False Positive)**：实际正确但报告失败
- **漏报(False Negative)**：实际错误但报告成功
- **重试(Retry)**：失败后重新执行
- **模糊匹配(Fuzzy Matching)**：非精确的相似度匹配

### 13.2 参考资料
- Playwright官方文档
- Sakura AI现有系统文档
- 竞品分析报告

---

*文档版本：1.0*
*创建日期：2024-11-04*
*作者：AI Assistant*
*状态：待评审*