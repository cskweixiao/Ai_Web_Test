// æµ‹è¯•å½“å‰ AI æ¨¡å‹çŠ¶æ€
async function testCurrentAIModel() {
  console.log('ğŸ§ª æµ‹è¯•å½“å‰ AI æ¨¡å‹çŠ¶æ€...\n');

  try {
    // 1. è·å–æœåŠ¡å™¨ç«¯é…ç½®
    console.log('1. è·å–å½“å‰æœåŠ¡å™¨ç«¯é…ç½®:');
    const response = await fetch('http://localhost:3001/api/config/llm');
    const config = await response.json();

    if (config.success) {
      console.log(`   âœ… å½“å‰æ¨¡å‹: ${config.data.summary.modelName}`);
      console.log(`   æ¨¡å‹ID: ${config.data.summary.modelId}`);
      console.log(`   æä¾›å•†: ${config.data.summary.provider}`);
      console.log(`   æ¸©åº¦: ${config.data.summary.temperature}`);
      console.log(`   æœ€å¤§ä»¤ç‰Œ: ${config.data.summary.maxTokens}`);
      console.log(`   æˆæœ¬çº§åˆ«: ${config.data.summary.costLevel}`);
      console.log(`   æ˜¯å¦å·²åˆå§‹åŒ–: ${config.data.summary.isInitialized}`);
    } else {
      console.log(`   âŒ è·å–é…ç½®å¤±è´¥: ${config.error}`);
    }

    // 2. æ¨¡æ‹Ÿä¸€ä¸ªç®€å•çš„ AI è§£æè¯·æ±‚æ¥éªŒè¯å®é™…ä½¿ç”¨çš„æ¨¡å‹
    console.log('\n2. æµ‹è¯• AI è§£æåŠŸèƒ½:');
    console.log('   æ³¨æ„ï¼šè¿™éœ€è¦åœ¨å®é™…çš„æµ‹è¯•æ‰§è¡Œä¸­æ‰èƒ½çœ‹åˆ° AI è°ƒç”¨æ—¥å¿—');
    console.log('   å»ºè®®ï¼šåœ¨å‰ç«¯é¡µé¢æ‰§è¡Œä¸€ä¸ªç®€å•çš„æµ‹è¯•ç”¨ä¾‹æ¥éªŒè¯');

    // 3. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ä¸­çš„æœ€æ–°è®°å½•
    console.log('\n3. å»ºè®®æ£€æŸ¥é¡¹ç›®:');
    console.log('   - æŸ¥çœ‹ debug-execution.log æ–‡ä»¶çš„æœ€æ–°æ—¥å¿—');
    console.log('   - åœ¨å‰ç«¯æ‰§è¡Œä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹');
    console.log('   - è§‚å¯Ÿ AI è°ƒç”¨æ—¶ä½¿ç”¨çš„æ¨¡å‹');

  } catch (error) {
    console.error('âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:', error);
  }
}

// è¿è¡Œæµ‹è¯•
testCurrentAIModel();